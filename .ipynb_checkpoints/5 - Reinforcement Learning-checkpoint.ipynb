{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCEMENT LEARNING\n",
    "* Entorno: las características del mundo donde vivirá un agente\n",
    "* Agente: Es el encargado de vivir en el entorno y tomar **acciones** a cambio recivirá **estados y recompensas**\n",
    "* Acciones: las decisiones que toma el angente en el entorno\n",
    "* Recompensa: tras una acción el agente recive una recompensa negativa o positiva\n",
    "* Estados: la recompensa recivida cambia, el estado actual que tenía el agente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La ecuación de Bellman\n",
    "* s = Estado\n",
    "* a = Acción\n",
    "* R = Recompensa\n",
    "* $\\gamma$ = Factor de descuento: sirve para que el estado actual no sea igual que el siguiente, Imaginemos que estamos en un juego, si no tenemos factor de descuento, el agente tomará decisiones aleatorias y se puede pasar una eternidad. Con el factor de descuento cada vez que toma una decisión hacemos que cada vez las recompensas sean menores, por lo que tras varios entrenamientos el agente trata de pasarse el juego lo más rápido posible para obtener una recompensa final mejor. En definitiva aceleramos el proceso de convergencia del algoritmo\n",
    "\n",
    "$$V(s) = max_a(R(s,a) + \\gamma V(s')) $$\n",
    "\n",
    "- Esta función es el valor que nos da el entorno en un estado concreto $V(s)$\n",
    "- El estado en el que nos vamos a encontrar después de una acción $V(s')$ \n",
    "- Hay que maximizar aquella opción que sea la mejor de todas las acciónes posibles (escoger la mejor) $max_a$\n",
    "- Dado un estado $s$, al elegir la opción $a$ la recompensa que voy a obtener en el estado actual tras tomar esa acciónb $R(s,a)$ a esto le sumarímos el valor que vamos a obtener tras moverme al nuevo estado $V(s')$, por tomar esa decisión, multiplicado por el factor de descuento $\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
